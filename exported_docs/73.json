{
  "id": 73,
  "title": "deepseek_aopml_engine",
  "body": "\"\"\"\naopml_engine.py \u2014 Aggressive OPML Engine for FunKit  # Changed filename reference\n\nGiven an input file (HTML or plain text), analyze and convert it into a\nstandards\u2011compliant OPML 2.0 document suitable for rendering in OPML readers.\n\nFeatures\n--------\n- HTML parsing respects heading structure (<h1>.. <h6>) and list items.\n- Plain text parsing infers section titles and breaks paragraphs into bullets\n  when markers are detected; otherwise preserves the text as a single note.\n- Optional AI assist: if `ai_interface.py` is available, the engine can\n  offload hard\u2011to\u2011parse sections to AI (on a worker thread) and merge results.\n- Zero external network usage unless `ai_interface` does so by design.\n\nIntended to be included in a future FunKit release.\n\nCLI\n---\npython aopml_engine.py INPUT_FILE [--title \"Custom Title\"] [--assume html|text]  # Updated script name\n                      [--ai] [--out out.opml]\n\nNotes\n-----\n- BeautifulSoup is used if available; otherwise the engine falls back to a\n  minimalist HTML heading extractor using html.parser.\n- The output is a *single* OPML document. Non\u2011hierarchical scraps are tucked\n  under an \"Unsorted\" section.\n\nAuthor: FunKit Team\nLicense: MIT\n\"\"\"\nfrom __future__ import annotations\n\nimport os\nimport re\nimport io\nimport sys\nimport time\nimport json\nimport uuid\nimport types\nimport typing as t\nimport logging\nfrom dataclasses import dataclass, field\nfrom xml.sax.saxutils import escape as xml_escape\n\n# --- Logging configuration -------------------------------------------------\nlogger = logging.getLogger(\"aopml_engine\")  # Updated logger name\nif not logger.handlers:\n    h = logging.StreamHandler()\n    h.setFormatter(logging.Formatter(\"[%(levelname)s] %(message)s\"))\n    logger.addHandler(h)\nlogger.setLevel(logging.INFO)\n\n# --- Optional imports ------------------------------------------------------\ntry:\n    from bs4 import BeautifulSoup  # type: ignore\n    _HAVE_BS4 = True\nexcept Exception:  # pragma: no cover\n    BeautifulSoup = None  # type: ignore\n    _HAVE_BS4 = False\n\ntry:\n    ai_interface = __import__(\"ai_interface\")\n    _HAVE_AI = True\nexcept Exception:\n    ai_interface = None\n    _HAVE_AI = False\n\n# --- OPML model ------------------------------------------------------------\n@dataclass\nclass Outline:\n    text: str\n    children: list[\"Outline\"] = field(default_factory=list)\n    _attrs: dict[str, str] = field(default_factory=dict)\n\n    def add(self, child: \"Outline\") -> None:\n        self.children.append(child)\n\n    def to_xml(self, indent: int = 2, level: int = 0) -> str:\n        pad = \" \" * (indent * level)\n        attrs = {\"text\": self.text}\n        attrs.update(self._attrs)\n        attr_str = \" \".join(f\"{k}=\\\"{xml_escape(v)}\\\"\" for k, v in attrs.items())\n        if not self.children:\n            return f\"{pad}<outline {attr_str}/>\\n\"\n        s = io.StringIO()\n        s.write(f\"{pad}<outline {attr_str}>\\n\")\n        for c in self.children:\n            s.write(c.to_xml(indent, level + 1))\n        s.write(f\"{pad}</outline>\\n\")\n        return s.getvalue()\n\n@dataclass\nclass OPMLDocument:\n    title: str\n    date_created: str = field(default_factory=lambda: time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()))\n    owner_name: str | None = None\n    outlines: list[Outline] = field(default_factory=list)\n    meta: dict[str, str] = field(default_factory=dict)\n\n    def to_xml(self, indent: int = 2) -> str:\n        head = io.StringIO()\n        head.write(\"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n\")\n        head.write(\"<opml version=\\\"2.0\\\">\\n\")\n        head.write(\"  <head>\\n\")\n        head.write(f\"    <title>{xml_escape(self.title)}</title>\\n\")\n        head.write(f\"    <dateCreated>{xml_escape(self.date_created)}</dateCreated>\\n\")\n        head.write(\"    <generator>FunKit AOPML Engine</generator>\\n\")\n        if self.owner_name:\n            head.write(f\"    <ownerName>{xml_escape(self.owner_name)}</ownerName>\\n\")\n        # Additional metadata\n        for k, v in self.meta.items():\n            head.write(f\"    <{k}>{xml_escape(v)}</{k}>\\n\")\n        head.write(\"  </head>\\n\")\n        head.write(\"  <body>\\n\")\n        body = io.StringIO()\n        for o in self.outlines:\n            body.write(o.to_xml(indent=indent, level=1))\n        tail = \"  </body>\\n</opml>\\n\"\n        return head.getvalue() + body.getvalue() + tail\n\n    def add(self, node: Outline) -> None:\n        self.outlines.append(node)\n\n# --- Heuristics ------------------------------------------------------------\n_HTML_SIGNS = re.compile(r\"<\\s*(!doctype|html|head|body|h[1-6]|p|div|ul|ol|li)\\b\", re.I)\n_LIST_MARK = re.compile(r\"^\\s*(?:[-*\u2022\u2023\u00b7]|\\d+[.)])\\s+\")\n_TITLE_LINE = re.compile(r\"^[\\t ]*([A-Z][^a-z\\n]{3,}|[#]{1,6}\\s+.+)$\")\n\n\ndef is_probably_html(text: str) -> bool:\n    return bool(_HTML_SIGNS.search(text))\n\n\ndef split_paragraphs(text: str) -> list[str]:\n    # Normalize newlines, keep paragraphs separated by blank lines\n    parts = re.split(r\"\\n\\s*\\n+\", text.strip())\n    return [p.strip() for p in parts if p.strip()]\n\n\ndef bulletize_lines(block: str) -> tuple[list[str] | None, str | None]:\n    \"\"\"Try to turn a block into bullets.\n    Returns (bullets, remainder). If cannot bulletize, returns (None, original).\n    \"\"\"\n    lines = [ln.rstrip() for ln in block.splitlines() if ln.strip()]\n    if not lines:\n        return None, None\n    if sum(bool(_LIST_MARK.match(ln)) for ln in lines) >= max(2, len(lines) // 2):\n        bullets = [re.sub(_LIST_MARK, \"\", ln).strip() for ln in lines if _LIST_MARK.match(ln)]\n        return bullets, None\n    # Heuristic: colon\u2011delimited or semicolon list in a sentence\n    if \":\" in block and any(ch in block for ch in \";,\u2022\"):\n        head, tail = block.split(\":\", 1)\n        # split by semicolons or bullet symbols\n        items = [it.strip(\" \\t-\u2022\u2023\u00b7\") for it in re.split(r\"[;\u2022\\u2022\\u25E6]|\\s\\-\\s\", tail) if it.strip()]\n        if len(items) >= 2 and all(len(it) <= 240 for it in items):\n            return items, head.strip()\n    return None, block\n\n# --- HTML parsing ----------------------------------------------------------\nclass _MiniHTMLHeadingParser:\n    \"\"\"Fallback HTML heading extractor using the standard library.\"\"\"\n\n    def __init__(self, html: str):\n        from html.parser import HTMLParser\n\n        self.headings: list[tuple[int, str]] = []\n\n        class HP(HTMLParser):\n            def __init__(self, outer: \"_MiniHTMLHeadingParser\"):\n                super().__init__(convert_charrefs=True)\n                self.outer = outer\n                self._in_h: int | None = None\n                self._buf: list[str] = []\n\n            def handle_starttag(self, tag: str, attrs):\n                if tag and len(tag) == 2 and tag[0] == \"h\" and tag[1].isdigit():\n                    lvl = int(tag[1])\n                    if 1 <= lvl <= 6:\n                        self._in_h = lvl\n                        self._buf.clear()\n\n            def handle_endtag(self, tag: str):\n                if self._in_h and tag == f\"h{self._in_h}\":\n                    text = \"\".join(self._buf).strip()\n                    if text:\n                        self.outer.headings.append((self._in_h, re.sub(r\"\\s+\", \" \", text)))\n                    self._in_h = None\n                    self._buf.clear()\n\n            def handle_data(selfdata: {\"id\":\"chatcmpl-e9e8126b42064c40b7b11d7e493c1740\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\", data: str\",\"function_call\":null,\"tool_calls\":[],\"role\":\"assistant\",\"refusal\":null},\"finish_reason\":null,\"logprobs\":null}],\"created\":1755969705,\"model\":\"baseten/DeepSeek-R1-0528-FP4\",\"service_tier\":null,\"system_fingerprint\":null,\"object\":\"chat.completion.chunk\",\"usage\":{\"prompt_tokens\":4510,\"completion_tokens\":4909,\"total_tokens\":9419,\"prompt_tokens_details\":null,\"completion_tokens_details\":null}}\n\ndata: {\"id\":\"chatcmpl-e9e8126b42064c40b7b11d7e493c1740\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"):\\n               \",\"function_call\":null,\"tool_calls\":[],\"role\":\"assistant\",\"refusal\":null},\"finish_reason\":null,\"logprobs\":null}],\"created\":1755969705,\"model\":\"baseten/DeepSeek-R1-0528-FP4\",\"service_tier\":null,\"system_fingerprint\":null,\"object\":\"chat.completion.chunk\",\"usage\":{\"prompt_tokens\":4510,\"completion_tokens\":4911,\"total_tokens\":9421,\"prompt_tokens_details\":null,\"completion_tokens_details\":null}}\n\ndata: {\"id\":\"chatcmpl-e9e8126b42064c40b7b11d7e493c1740\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" if self._\",\"function_call\":null,\"tool_calls\":[],\"role\":\"assistant\",\"refusal\":null},\"finish_reason\":null,\"logprobs\":null}],\"created\":1755969705,\"model\":\"baseten/DeepSeek-R1-0528-FP4\",\"service_tier\":null,\"system_fingerprint\":null,\"object\":\"chat.completion.chunk\",\"usage\":{\"prompt_tokens\":4510,\"completion_tokens\":4914,\"total_tokens\":9424,\"prompt_tokens_details\":null,\"completion_tokens_details\":null}}\n\ndata: {\"id\":\"chatcmpl-e9e8126b42064c40b7b11d7e493c1740\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"in_h\",\"function_call\":null,\"tool_calls\":[],\"role\":\"assistant\",\"refusal\":null},\"finish_reason\":null,\"logprobs\":null}],\"created\":1755969705,\"model\":\"baseten/DeepSeek-R1-0528-FP4\",\"service_tier\":null,\"system_fingerprint\":null,\"object\":\"chat.completion.chunk\",\"usage\":{\"prompt_tokens\":4510,\"completion_tokens\":4916,\"total_tokens\":9426,\"prompt_tokens_details\":null,\"completion_tokens_details\":null}}\n\ndata: {\"id\":\"chatcmpl-e9e8126b42064c40b7b11d7e493c1740\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\":\\n                    self\",\"function_call\":null,\"tool_calls\":[],\"role\":\"assistant\",\"refusal\":null},\"finish_reason\":null,\"logprobs\":null}],\"created\":1755969705,\"model\":\"baseten/DeepSeek-R1-0528-FP4\",\"service_tier\":null,\"system_fingerprint\":null,\"object\":\"chat.completion.chunk\",\"usage\":{\"prompt_tokens\":4510,\"completion_tokens\":4919,\"total_tokens\":9429,\"prompt_tokens_details\":null,\"completion_tokens_details\":null}}\n\ndata: {\"id\":\"chatcmpl-e9e8126b42064c40b7b11d7e493c1740\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"._buf.append\",\"function_call\":null,\"tool_calls\":[],\"role\":\"assistant\",\"refusal\":null},\"finish_reason\":null,\"logprobs\":null}],\"created\":1755969705,\"model\":\"baseten/DeepSeek-R1-0528-FP4\",\"service_tier\":null,\"system_fingerprint\":null,\"object\":\"chat.completion.chunk\",\"usage\":{\"prompt_tokens\":4510,\"completion_tokens\":4922,\"total_tokens\":9432,\"prompt_tokens_details\":null,\"completion_tokens_details\":null}}\n\ndata: {\"id\":\"chatcmpl-e9e8126b42064c40b7b11d7e493c1740\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"(data)\\n\\n       \",\"function_call\":null,\"tool_calls\":[],\"role\":\"assistant\",\"refusal\":null},\"finish_reason\":null,\"logprobs\":null}],\"created\":1755969705,\"model\":\"baseten/DeepSeek-R1-0528-FP4\",\"service_tier\":null,\"system_fingerprint\":null,\"object\":\"chat.completion.chunk\",\"usage\":{\"prompt_tokens\":4510,\"completion_tokens\":4925,\"total_tokens\":9435,\"prompt_tokens_details\":null,\"completion_tokens_details\":null}}\n\ndata: {\"id\":\"chatcmpl-e9e8126b42064c40b7b11d7e493c1740\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" HP(self).\",\"function_call\":null,\"tool_calls\":[],\"role\":\"assistant\",\"refusal\":null},\"finish_reason\":null,\"logprobs\":null}],\"created\":1755969705,\"model\":\"baseten/DeepSeek-R1-0528-FP4\",\"service_tier\":null,\"system_fingerprint\":null,\"object\":\"chat.completion.chunk\",\"usage\":{\"prompt_tokens\":4510,\"completion_tokens\":4928,\"total_tokens\":9438,\"prompt_tokens_details\":null,\"completion_tokens_details\":null}}\n\ndata: {\"id\":\"chatcmpl-e9e8126b42064c40b7b11d7e493c1740\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"feed(html\",\"function_call\":null,\"tool_calls\":[],\"role\":\"assistant\",\"refusal\":null},\"finish_reason\":null,\"logprobs\":null}],\"created\":1755969705,\"model\":\"baseten/DeepSeek-R1-0528-FP4\",\"service_tier\":null,\"system_fingerprint\":null,\"object\":\"chat.completion.chunk\",\"usage\":{\"prompt_tokens\":4510,\"completion_tokens\":4931,\"total_tokens\":9441,\"prompt_tokens_details\":null,\"completion_tokens_details\":null}}\n\ndata: {\"id\":\"chatcmpl-e9e8126b42064c40b7b11d7e493c1740\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\")\\n\\n   \",\"function_call\":null,\"tool_calls\":[],\"role\":\"assistant\",\"refusal\":null},\"finish_reason\":null,\"logprobs\":null}],\"created\":1755969705,\"model\":\"baseten/DeepSeek-R1-0528-FP4\",\"service_tier\":null,\"system_fingerprint\":null,\"object\":\"chat.completion.chunk\",\"usage\":{\"prompt_tokens\":4510,\"completion_tokens\":4933,\"total_tokens\":9443,\"prompt_tokens_details\":null,\"completion_tokens_details\":null}}\n\ndata: {\"id\":\"chatcmpl-e9e8126b42064c40b7b11d7e493c1740\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" def to\",\"function_call\":null,\"tool_calls\":[],\"role\":\"assistant\",\"refusal\":null},\"finish_reason\":null,\"logprobs\":null}],\"created\":1755969705,\"model\":\"baseten/DeepSeek-R1-0528-FP4\",\"service_tier\":null,\"system_fingerprint\":null,\"object\":\"chat.completion.chunk\",\"usage\":{\"prompt_tokens\":4510,\"completion_tokens\":4935,\"total_tokens\":9445,\"prompt_tokens_details\":null,\"completion_tokens_details\":null}}\n\ndata: {\"id\":\"chatcmpl-e9e8126b42064c40b7b11d7e493c1740\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"_outline(self\",\"function_call\":null,\"tool_calls\":[],\"role\":\"assistant\",\"refusal\":null},\"finish_reason\":null,\"logprobs\":null}],\"created\":1755969705,\"model\":\"baseten/DeepSeek-R1-0528-FP4\",\"service_tier\":null,\"system_fingerprint\":null,\"object\":\"chat.completion.chunk\",\"usage\":{\"prompt_tokens\":4510,\"completion_tokens\":4938,\"total_tokens\":9448,\"prompt_tokens_details\":null,\"completion_tokens_details\":null}}\n\n) -> Outline:\n        root = Outline(\"Document\")\n        stack: list[tuple[int, Outline]] = [(0, root)]\n        for lvl, text in self.headings:\n            node = Outline(text)\n            while stack and lvl <= stack[-1][0]:\n                stack.pop()\n            stack[-1][1].add(node)\n            stack.append((lvl, node))\n        return root\n\n\ndef html_to_outline(html: str) -> Outline:\n    if _HAVE_BS4:\n        soup = BeautifulSoup(html, \"html.parser\")\n        title = (soup.title.string or \"\").strip() if soup.title and soup.title.string else None\n        root = Outline(title or \"Document\")\n        stack: list[tuple[int, Outline]] = [(0, root)]\n        body = soup.body or soup\n        for el in body.descendants:\n            if getattr(el, \"name\", None) and re.fullmatch(r\"h[1-6]\", el.name or \"\", re.I):\n                lvl = int(el.name[1])\n                text = el.get_text(\" \", strip=True)\n                node = Outline(text)\n                while stack and lvl <= stack[-1][0]:\n                    stack.pop()\n                stack[-1][1].add(node)\n                stack.append((lvl, node))\n            elif getattr(el, \"name\", None) in {\"ul\", \"ol\"}:\n                # attach list to the most recent heading\n                if stack:\n                    parent = stack[-1][1]\n                    lst = Outline(\"List\")\n                    for li in el.find_all(\"li\", recursive=False):\n                        txt = li.get_text(\" \", strip=True)\n                        if txt:\n                            lst.add(Outline(txt))\n                    if lst.children:\n                        parent.add(lst)\n            # paragraphs not under any heading become Unsorted\n        # Capture stray paragraphs at top level\n        unsorted = Outline(\"Unsorted\")\n        for p in body.find_all(\"p\", recursive=True):\n            txt = p.get_text(\" \", strip=True)\n            if txt:\n                unsorted.add(Outline(txt))\n        if unsorted.children:\n            root.add(unsorted)\n        return root\n    else:\n        logger.debug(\"bs4 not available; using minimal parser\")\n        return _MiniHTMLHeadingParser(html).to_outline()\n\n# --- Plain text parsing ----------------------------------------------------\n\ndef text_to_outline(text: str, assumed_title: str | None = None) -> Outline:\n    lines = [ln.rstrip() for ln in text.splitlines()]\n    # Infer title: first underlined or ATX heading (# Title) or ALLCAPS line\n    title: str | None = None\n    for i, ln in enumerate(lines[:8]):\n        if ln.strip().startswith(\"# \"):\n            title = ln.strip(\"# \").strip()\n            lines = lines[i + 1 :]\n            break\n        if i + 1 < len(lines) and set(lines[i + 1].strip()) in ({\"=\"}, {\"-\"}) and len(lines[i + 1].strip()) >= max(3, len(ln.strip()) // 2):\n            title = ln.strip()\n            lines = lines[i + 2 :]\n            break\n        if _TITLE_LINE.match(ln):\n            title = ln.strip(\"# \").strip()\n            lines = lines[i + 1 :]\n            break\n    title = title or assumed_title or \"Document\"\n    root = Outline(title)\n\n    # Group paragraphs\n    text_body = \"\\n\".join(lines)\n    paras = split_paragraphs(text_body)\n    for para in paras:\n        bullets, remainder = bulletize_lines(para)\n        if bullets is not None:\n            # Heading + bullets\n            head_text = remainder if remainder else para.split(\"\\n\", 1)[0][:60]\n            section = Outline(head_text if head_text else \"List\")\n            for b in bullets:\n                section.add(Outline(b))\n            root.add(section)\n        else:\n            root.add(Outline(para))\n    return root\n\n# --- AI assist -------------------------------------------------------------\n@dataclass\nclass AITask:\n    section_id: str\n    original: str\n    result_xml: str | None = None\n    error: str | None = None\n\n\ndef _ai_worker(tasks: list[AITask]):  # pragma: no cover (side\u2011effectful)\n    if not _HAVE_AI:\n        return\n    try:\n        for tsk in tasks:\n            try:\n                # Expected contract: ai_interface.suggest_opml(text:str) -> OPML outline XML (string)\n                if hasattr(ai_interface, \"suggest_opml\"):\n                    tsk.result_xml = ai_interface.suggest_opml(tsk.original)\n                elif hasattr(ai_interface, \"process_text_to_opml\"):\n                    tsk.result_xml = ai_interface.process_text_to_opml(tsk.original)\n                else:\n                    tsk.error = \"ai_interface lacks suggest_opml/process_text_to_opml\"\n            except Exception as e:  # noqa: BLE001\n                tsk.error = f\"AI error: {e}\"\n    except Exception as e:  # noqa: BLE001\n        logger.error(\"AI worker failed: %s\", e)\n\n\n# --- Public API ------------------------------------------------------------\n\n# ---- Engine config (single, top-level) ----\nfrom dataclasses import dataclass\n\n@dataclass\nclass EngineConfig:\n    enable_ai: bool = False\n    owner_name: str | None = None\n    owner_email: str | None = None\n    title: str | None = None\n\n\n# ---- small helper: tolerate cfg as object/dict/str/None ----\ndef _cfg_get(cfg, key, default=\"\"):\n    if cfg is None:\n        return default\n    if isinstance(cfg, dict):\n        return cfg.get(key, default)\n    return getattr(cfg, key, default)\n\n\n# ---- central entry the plugin prefers ----\ndef convert_payload_to_opml(title: str, payload, cfg: EngineConfig | dict | None = None) -> str:\n    \"\"\"\n    Main entry point used by opml_extras_plugin.\n    Detects HTML vs text and routes accordingly.\n    Returns XML text.\n    \"\"\"\n    text = payload.decode(\"utf-8\", \"replace\") if isinstance(payload, (bytes, bytearray)) else str(payload or \"\")\n    low = text.lower()\n    if (\"<html\" in low) or (\"<body\" in low) or (\"<div\" in low) or (\"<p\" in low):\n        doc = build_opml_from_html(title, text, cfg=cfg)\n    else:\n        doc = build_opml_from_text(title, text, cfg=cfg)\n    return doc.to_xml()  # assumes OPMLDocument has .to_xml()\n\n\n# ---- robust HTML path ----\ndef build_opml_from_html(title: str, html: str, cfg: EngineConfig | dict | None = None):\n    \"\"\"\n    Parse HTML \u2192 outline \u2192 OPMLDocument (no owner fields).\n    \"\"\"\n    outline = html_to_outline(html)\n\n    _cfg_title   = _cfg_get(cfg, \"title\", \"\")\n    _final_title = (outline.text or _cfg_title or title or \"Document\")\n\n    # OPMLDocument doesn\u2019t accept owner_* \u2192 don\u2019t pass them\n    doc = OPMLDocument(title=_final_title)\n\n    # Transfer structure if any; otherwise add a single node\n    for child in getattr(outline, \"children\", []):\n        doc.add(child)\n    if not getattr(outline, \"children\", []):\n        doc.add(Outline(outline.text or _final_title))\n\n    return doc\n\n\n# ---- robust TEXT path ----\n\ndef build_opml_from_text(title: str, text: str, cfg: EngineConfig | dict | None = None):\n    \"\"\"\n    Parse plain text \u2192 outline \u2192 OPMLDocument (no owner fields).\n    \"\"\"\n    outline = text_to_outline(text, assumed_title=_cfg_get(cfg, \"title\", None))\n\n    _cfg_title   = _cfg_get(cfg, \"title\", \"\")\n    _final_title = (outline.text or _cfg_title or title or \"Document\")\n\n    # OPMLDocument doesn\u2019t accept owner_* \u2192 don\u2019t pass them\n    doc = OPMLDocument(title=_final_title)\n\n    for child in getattr(outline, \"children\", []):\n        doc.add(child)\n    if not getattr(outline, \"children\", []):\n        doc.add(Outline(outline.text or _final_title))\n\n    return doc\n\n\ndef build_opml_from_file(path: str, cfg: EngineConfig | None = None) -> OPMLDocument:\n    cfg = cfg or EngineConfig()\n    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n        data = f.read()\n    if is_probably_html(data):\n        logger.info(\"Detected HTML input\")\n        return build_opml_from_html(data, cfg)\n    else:\n        logger.info(\"Detected TEXT input\")\n        return build_opml_from_text(data, cfg)\n\n\n# --- CLI ------------------------------------------------------------------\n\ndef _parse_argv(argv: list[str]) -> dict:\n    import argparse\n\n    p = argparse.ArgumentParser(description=\"FunKit AOPML Engine \u2014 HTML/TEXT to OPML\")\n    p.add_argument(\"input\", help=\"Input file path (HTML or text)\")\n    p.add_argument(\"--title\", dest=\"title\", default=None, help=\"Override OPML title\")\n    p.add_argument(\"--assume\", choices=[\"html\", \"text\"], help=\"Assume input type, bypass detection\")\n    p.add_argument(\"--ai\", action=\"store_true\", help=\"Enable AI assist if ai_interface is present\")\n    p.add_argument(\"--owner\", default=None, help=\"Owner name for OPML head\")\n    p.add_argument(\"--out\", default=None, help=\"Output .opml path (default: input with .opml)\")\n    p.add_argument(\"--debug\", action=\"store_true\", help=\"Verbose logs\")\n    ns = p.parse_args(argv)\n    if ns.debug:\n        logger.setLevel(logging.DEBUG)\n    return {\n        \"input\": ns.input,\n        \"title\": ns.title,\n        \"assume\": ns.assume,\n        \"enable_ai\": bool(ns.ai),\n        \"owner\": ns.owner,\n        \"out\": ns.out,\n    }\n\n\ndef main(argv: list[str] | None = None) -> int:\n    args = _parse_argv(argv or sys.argv[1:])\n    cfg = EngineConfig(enable_ai=args[\"enable_ai\"], owner_name=args[\"owner\"], title=args[\"title\"])\n    path = args[\"input\"]\n    if not os.path.exists(path):\n        logger.error(\"Input not found: %s\", path)\n        return 2\n\n    # Bypass detection if requested\n    if args[\"assume\"] == \"html\":\n        with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n            html = f.read()\n        doc = build_opml_from_html(html, cfg)\n    elif args[\"assume\"] == \"text\":\n        with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n            txt = f.read()\n        doc = build_opml_from_text(txt, cfg)\n    else:\n        doc = build_opml_from_file(path, cfg)\n\n    out_path = args[\"out\"] or os.path.splitext(path)[0] + \".opml\"\n    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(doc.to_xml())\n    logger.info(\"Wrote OPML: %s\", out_path)\n    return 0\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    raise SystemExit(main())\n"
}